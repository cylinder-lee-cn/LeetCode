"""
雪花算法

Snowflake中文的意思是：雪花、雪片，因此翻译成雪花算法。
它最早是twitter内部使用的分布式环境下的唯一ID生成算法。在2014年开源。
开源的版本由scala编写。

https://github.com/twitter-archive/snowflake/tags

雪花算法产生的背景是twitter高并发环境下对唯一ID生成的需求，得益于Twitter的技术，
雪花算法流传至今并被广泛使用。它至少有如下几个特点：

* 能满足高并发分布式系统环境下ID不重复
* 基于时间戳，可以保证基本有序递增（有些业务场景对这个有要求）
* 不依赖第三方的库或者中间件
* 生成效率极高

雪花算法原理

雪花算法的原理其实非常简单，也是该算法能广为流传的原因之一。

算法产生的是一个long型 64 比特位的值，第一位未使用。接下来是41位的毫秒单位的时间戳，计算一下：

2^41/1000*60*60*24*365 = 69

也就是这个时间戳可以使用69年不重复，这个对于绝大部分系统够用了。

很多人这里会搞错概念，以为这个时间戳是相对于一个我们业务中指定的时间（一般是系统上线时间），
而不是1970年。这里一定要注意。

10位的数据机器位，所以可以部署在1024个节点。

12位的序列，在毫秒的时间戳内计数。 支持每个节点每毫秒产生4096个ID序号，
所以最大可以支持单节点差不多四百万的并发量，这个妥妥的够用了。

《Snowflake.jpg》

基于这个原例，针对特定的场景可以对雪花算法的取位进行调整
* 依旧保持64位
* 二进制最大是 0111111111111111111111111111111111111111111111111111111111111111
* 十进制最大是 9223372036854775807 （与Mysql的bigint一致）
* Sign（1 bit） 0
* Delta Seconds（32 bits）精度到秒，最多可以支持到8.5年左右
* Work ID（16 bits），Work ID还可以细分成几段，分别提供给不同的系统或小组使用
* Sequence （15 bits）每秒最多可以生成32768个序列号，也就是每秒可以承受3.2W的并发
1+32+16+15=64
"""

import time

WorkIDBits = 16
SequenceBits = 15
MaxWorkID = 65535
MinSequence = 0
maxSequence = 32767


class Snowflake:
    def __init__(self, workid):
        pass

    def newID(self):
        timeStamp = int(time.time())


s = Snowflake(0b0000000000000000)

s.newID()
